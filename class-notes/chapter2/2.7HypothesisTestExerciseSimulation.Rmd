In the next chunck of R code data are simulated under the null hypothesis  
$\hat{\beta_1} = 0$ , because the type I error rate is the probability to reject the 
null hypothesis, given that the null hypothesis is true. For each repeated 
sample we compute the p-value for the one-sided alternative that is 
determined by the sign of the parameter estimate  $\hat{\beta_1}$
 .
```{r}
set.seed(87175)
N <- 10000 # number of repeated experiments
x <- c(165, 170, 175, 180, 185) # five father's heights
X <- cbind(1, x) # design matrix
pvalues <- c()
for (i in 1:N) {
  y <- 90 + 0 * x + rnorm(5, sd = 5) # random sample of 5 outcomes -- we simulate under H_0:beta1=0
  m <- lm(y ~ x)
  beta1Hat <- coef(m)[2]
  if (beta1Hat < 0) {
    p <- summary(m)$coef[2, 4] / 2 # if t<0, the p-value for H_1: beta1<0 needs to be devided by 2
  }
  if (beta1Hat > 0) {
    p <- summary(m)$coef[2, 4] / 2 # if t>0, the p-value for H_1: beta1>0 needs to be devided by 2
  }
  pvalues <- c(pvalues, p)
}

# empirical type I error rate for alpha=0.05
mean(pvalues < 0.05)
```
```{r}
hist(pvalues,
  cex.lab = 1.5, cex.axis = 1.5,
  xlim = c(0, 1)
)
```